{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DCGAN para Fashion-MNIST\n",
    "Desarrollado siguiendo el ejemplo de [pyimagesearch](https://www.pyimagesearch.com/2021/11/11/get-started-dcgan-for-fashion-mnist/).\n",
    "Esta basado en el paper [Unsupervised Representation Learning with Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434).\n",
    "Fue uno de los primeros papers dedicados a GAN y es un Must-Read si quieres utilizar GAN\n",
    "\n",
    "En este notebook se trabajaran los siguientes temas:\n",
    "\n",
    "    1. Guidelines de la arquitectura DCGAN\n",
    "    2. `train_step()` personalizado con Keras `model.fit()`\n",
    "    3. Implementación de DCGAN con TensorFlow 2 y Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Guias de arquitectura para estabilidad del entrenamiento\n",
    "\n",
    "Guidelines de arquitectura para GANs Convolucionales Profundas estables.\n",
    "\n",
    "\n",
    "   - Reemplaza las capas de Pooling con convoluciones strided (discriminador) y convoluciones fraccionales\n",
    "    strided (generador).\n",
    "   - Utiliza batch normalization in el generador y discriminador.\n",
    "   - Remueve las capas ocultas densamente conectadas para arquitecturas profundas.\n",
    "   - Usa la activación ReLU en el **generador para todas** las capas excepto por la de salida, la cuál usa Tanh.\n",
    "   - Usa la activación LeakyReLU en el **discriminador para todas** las capas\n",
    "\n",
    "## Guidelines:\n",
    "### Convolutions\n",
    "\n",
    "    - __Strided Convolutions:__ Capa convolucional con un paso de 2 utilizado para downsamplear al Discriminador.\n",
    "    - **Fractional-Strided Convolutions:** ´Conv2DTranspose´, capoa con un paso de 2 para upsamplear en el Generador.\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "Utilizar normalización de batch tanto en el Generador (**G**) como en el Discriminador (**D**) ayudan a estabilizar\n",
    "el entrenamiento de una GAN. La normalización de lotes estandariza la capa de entrada a tener una media de cero y una\n",
    "varianza unitaria. Se suele añadir luego de la capa oculta y antes de la capa de activación.\n",
    "\n",
    "## Activación.\n",
    "\n",
    "Actualmente son 4 funciones de activación las mas utilizadas para DCGAN tanto para **G** como para **D**:\n",
    "\n",
    "    - **sigmoide**: Comprime el número desde 0 hasta 1. Debido a que **D** realiza una clasificación binaria, se\n",
    "    utiliza para la ultima capa de **D**.\n",
    "    - **tanh**: También llamada s-shaped similar a Sigmoide. Es un Sigmoide escalado pero centrado a 0 y mapea\n",
    "    el valor de la entrada a un rango de [-1, 1]. Se utilizará para la ultima capa de **G**, razón por la cuál\n",
    "    preprocesaremos las imagenes de entrenamiento en el rango de [-1, 1].\n",
    "    - **ReLU**: Retorna 0 cuando la entrada es negativa, cualquier otro valor lo regresa tal cual. El artículo recomienda\n",
    "    utilizar ReLU para todas las capas de **G** menos la de salida, la cuál utiliza **tanh**\n",
    "    - **leakyReLU**: Similar a ReLU con la excepción de que el valor de entrada es negativa, pues utiliza una constante\n",
    "    *alpha*, la cuál da una pequeña inclinación líneal. Como suguiere el artículo, alpha se define en 0.2. En este\n",
    "    caso utilizarémos LeakyReLU para todas las capas de **D** menos la ultima."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DCGAN en Keras\n",
    "\n",
    "El proceso se divide en 6 etapas:\n",
    "\n",
    "    1 Dependenias: Carga de librerias.\n",
    "    2 Preprocesamiento de datos: Preparación del dataset, carga, visualización.\n",
    "    3 Generador: Construcción de la red Generador.\n",
    "    4 Discriminador: Construcción de la red discriminadora.\n",
    "    5 DCGAN: Se mezclan los dos anteriores y se define el modelo.\n",
    "    6 Keras_Callback: Monitoreo durante el entrenamiento.\n",
    "    7 Training: DCGAN, Compilar, entrenar.\n",
    "\n",
    "Similar a las GAN originales, se entrenan las dos redes de manera simultanea, el Generador y el Discriminador.\n",
    "Para crear el modelo DCGAN, hay que definir la arquitectura del generador y el discriminador con el API de Keras.\n",
    "Finalmente, utilizar la sublase de Keras Model para crear la DCGAN.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}